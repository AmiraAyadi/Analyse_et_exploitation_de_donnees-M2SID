from scipy.misc import imread, imsave
import matplotlib.pyplot as plt
from scipy import linalg
import numpy as np
import os 


# Constantes
person = ['fcmr0', 'fcrh0', 'fdac1', 'fdms0', 'fdrd1', 'fedw0', 'felc0', 'fgjd0']
rep_APP = 'APP'
rep_TEST = 'TEST'
nb_images_APP = 1
nb_images_TEST = 1
save_fig = True


# APPRENTISSAGE

# a) Lecture de toutes les images d'apprentissage en niveaux de gris et transformation en vecteurs pour faciliter les calculs

debut = True
for x in person:
    for i in range(1,nb_images_APP +1):
        #creation du nom 
        nom = "./Data/" +x+ "/" + rep_APP + "/00" +str(i)
        # lecture du fichier nom 
        img = np.array(imread(nom,True))
        dim = img.shape # ou dim = np.shape(img)
        #stockage image en vecteur 
        im = img.flatten()
        if debut == True:
            imgs = im
            debut = False
        else : 
            imgs = np.vstack((imgs,im))

# b) Calcul de l'image moyenne
# il faut faire la moyenne selon un axe. 
# np.mean(elm,axe) pour faire la moyenne selon l'axe demandé
moyenne = np.mean(imgs,axis=0)
imgs_moy = moyenne.reshape(dim[0], dim[1])
plt.imshow(imgs_moy, cmap='Greys_r')

# Transformation du vecteur moyenne en matrice hxl et enregistrement
if save_fig:
    imsave("./TEMP/average.png", imgs_moy)

# c) Calcul de M = image - moyenne

M = imgs - moyenne
plt.imshow(moyenne.reshape(dim[0],dim[1]), cmap='Greys_r')

# d) svd : Singular Value Decomposition
# eigenfaces : matrice unitaire dont les vecteurs singuliers sont en colonnes
# Les colonnes de eigenfaces sont des vecteurs propres

M_trans = M.T
eigenfaces,sigma,v = np.linalg.svd(M_trans, full_matrices = False)

# Enregistrement des vecteurs eigenfaces
if save_fig:
    for i in range(eigenfaces.shape[1]): # eigenfaces.shape[1] = nombre de colonnes = N
        imsave("./TEMP/" + str(i) + ".png", eigenfaces[:,i].reshape(dim[0], dim[1]))
        
# e) Calcul des poids associés à chaque visages propres
poids = np.dot(M, eigenfaces)

# Reconstruction de visages
# On obtient un jeu de N² images reconstituées
if save_fig:
    for p in range(len(person)):
        for i in range(len(person)):
            recon = moyenne + np.dot(poids[p, :i], eigenfaces[:, :i].T)
            img_id = str(p)+"_"+str(i)
            imsave("TEMP/"+ img_id + ".png", recon.reshape(dim[0], dim[1]))

			
# RECONNAISSANCE
# a) Tester chaque image
result= []
for rep in person:
    img = os.listdir("Data/"+rep+"/"+rep_APP+"/")
    # Lecture de l'image puis mise en vecteur
    img_t = imread("Data/"+rep+"/"+rep_APP+"/"+img[0], mode="L").flatten()
    # Soustraction de l'image moyenne
    img_centre = img_t - moyenne
    # Calcul des poids associés à chaque visages propres
    proj = np.dot(img_centre, eigenfaces)
    # Chercher la personne la plus proche dans le nouvel espace
    distance = np.sum(np.sqrt(np.power(poids - proj, 2)), 1)
    res = person[np.argmin(distance)]
    result.append(res)
    print("Personne cible --> " + rep + " - Personne reconnue --> " + res)

print("Taux de reussite : {}".format(sum([100*(result[i]==person[i])/len(person) for i in range(len(person))])))

# Affichage du score global

# Tests avec une seule image par personne
result = []
for rep in person:
    img = os.listdir("Data/"+rep+"/"+rep_TEST+"/")
    # Lecture de l'image puis mise en vecteur
    img_t = imread("Data/"+rep+"/"+rep_TEST+"/"+img[0], mode="L").flatten()
    # Soustraction de l'image moyenne
    img_centre = img_t - moyenne
    # Calcul des poids associés à chaque visages propres
    proj = np.dot(img_centre, eigenfaces)
    # Chercher la personne la plus proche dans le nouvel espace
    distance = np.sum(np.sqrt(np.power(poids - proj, 2)), 1)
    res = person[np.argmin(distance)]
    result.append(res)
    res = result[-1]





        # Affichage des résultats
        #print("Distance min : " + str(mindist) + "Indice min : " + str(indiceImg))
    print("Personne cible --> " + x + " - Personne reconnue --> " + y)

print("Taux de reussite : {}".format(sum([100*(result_p[i]==person[i])/len(person) for i in range(len(person))])))

# Affichage du score global
#expliqué pouorquoi quand on entraine sur ces fichier et qu'on test sur le tout on tombe que sur 37%  pouor le rapport gros plus !

